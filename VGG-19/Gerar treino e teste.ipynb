{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dropout, Flatten, Dense  \n",
    "from keras import applications  \n",
    "from keras.utils.np_utils import to_categorical  \n",
    "import matplotlib.pyplot as plt  \n",
    "import math  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dimensoes de entrada da VGG19\n",
    "img_width, img_height = 224, 224  \n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "#Path dos dados a serem utilizados\n",
    "data_dir40 = '../Dados/breast_cancer40'\n",
    "data_dir100 = '../Dados/breast_cancer100'\n",
    "data_dir200 = '../Dados/breast_cancer200'\n",
    "data_dir400 = '../Dados/breast_cancer400'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados 40x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1995 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#Carregando fator 40x\n",
    "generator40 = datagen.flow_from_directory(\n",
    "    data_dir40,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "#Features extraidas\n",
    "data40 = np.load('bottleneck_features_40.npy')\n",
    "len_Data_40 = len(data40)\n",
    "data40 = data40.reshape(len_Data_40,-1)\n",
    "#Labels em ordem dos dados\n",
    "labels40 = generator40.classes\n",
    "num_classes40 = len(generator40.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar 5 divisoes do conjunto em treino e teste de magnitude 40x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X40_train1, X40_test1, y40_train1, y40_test1 = train_test_split(data40, labels40, random_state=0, train_size=0.7)\n",
    "X40_train2, X40_test2, y40_train2, y40_test2 = train_test_split(data40, labels40, random_state=1, train_size=0.7)\n",
    "X40_train3, X40_test3, y40_train3, y40_test3 = train_test_split(data40, labels40, random_state=2, train_size=0.7)\n",
    "X40_train4, X40_test4, y40_train4, y40_test4 = train_test_split(data40, labels40, random_state=3, train_size=0.7)\n",
    "X40_train5, X40_test5, y40_train5, y40_test5 = train_test_split(data40, labels40, random_state=4, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar os dados de treino e teste e labels magnitude 40x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('X40_train1.npy', X40_train1)\n",
    "np.save('X40_train2.npy', X40_train2)\n",
    "np.save('X40_train3.npy', X40_train3)\n",
    "np.save('X40_train4.npy', X40_train4)\n",
    "np.save('X40_train5.npy', X40_train5)\n",
    "\n",
    "np.save('X40_test1.npy', X40_test1)\n",
    "np.save('X40_test2.npy', X40_test2)\n",
    "np.save('X40_test3.npy', X40_test3)\n",
    "np.save('X40_test4.npy', X40_test4)\n",
    "np.save('X40_test5.npy', X40_test5)\n",
    "\n",
    "np.save('y40_train1.npy', y40_train1)\n",
    "np.save('y40_train2.npy', y40_train2)\n",
    "np.save('y40_train3.npy', y40_train3)\n",
    "np.save('y40_train4.npy', y40_train4)\n",
    "np.save('y40_train5.npy', y40_train5)\n",
    "\n",
    "np.save('y40_test1.npy', y40_test1)\n",
    "np.save('y40_test2.npy', y40_test2)\n",
    "np.save('y40_test3.npy', y40_test3)\n",
    "np.save('y40_test4.npy', y40_test4)\n",
    "np.save('y40_test5.npy', y40_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados 100x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2081 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#Carregando fator 100x\n",
    "generator100 = datagen.flow_from_directory(\n",
    "    data_dir100,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "#Features extraidas\n",
    "data100 = np.load('bottleneck_features_100.npy')\n",
    "len_Data_100 = len(data100)\n",
    "data100 = data100.reshape(len_Data_100,-1)\n",
    "#Labels em ordem dos dados\n",
    "labels100 = generator100.classes\n",
    "num_classes100 = len(generator100.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar 5 divisoes do conjunto em treino e teste de magnitude 100x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X100_train1, X100_test1, y100_train1, y100_test1 = train_test_split(data100, labels100, random_state=0, train_size=0.7)\n",
    "X100_train2, X100_test2, y100_train2, y100_test2 = train_test_split(data100, labels100, random_state=1, train_size=0.7)\n",
    "X100_train3, X100_test3, y100_train3, y100_test3 = train_test_split(data100, labels100, random_state=2, train_size=0.7)\n",
    "X100_train4, X100_test4, y100_train4, y100_test4 = train_test_split(data100, labels100, random_state=3, train_size=0.7)\n",
    "X100_train5, X100_test5, y100_train5, y100_test5 = train_test_split(data100, labels100, random_state=4, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar os dados de treino e teste e labels magnitude 100x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('X100_train1.npy', X100_train1)\n",
    "np.save('X100_train2.npy', X100_train2)\n",
    "np.save('X100_train3.npy', X100_train3)\n",
    "np.save('X100_train4.npy', X100_train4)\n",
    "np.save('X100_train5.npy', X100_train5)\n",
    "\n",
    "np.save('X100_test1.npy', X100_test1)\n",
    "np.save('X100_test2.npy', X100_test2)\n",
    "np.save('X100_test3.npy', X100_test3)\n",
    "np.save('X100_test4.npy', X100_test4)\n",
    "np.save('X100_test5.npy', X100_test5)\n",
    "\n",
    "np.save('y100_train1.npy', y100_train1)\n",
    "np.save('y100_train2.npy', y100_train2)\n",
    "np.save('y100_train3.npy', y100_train3)\n",
    "np.save('y100_train4.npy', y100_train4)\n",
    "np.save('y100_train5.npy', y100_train5)\n",
    "\n",
    "np.save('y100_test1.npy', y100_test1)\n",
    "np.save('y100_test2.npy', y100_test2)\n",
    "np.save('y100_test3.npy', y100_test3)\n",
    "np.save('y100_test4.npy', y100_test4)\n",
    "np.save('y100_test5.npy', y100_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados 200x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2013 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#Carregando fator 200x\n",
    "generator200 = datagen.flow_from_directory(\n",
    "    data_dir200,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "#Features extraidas\n",
    "data200 = np.load('bottleneck_features_200.npy')\n",
    "len_Data_200 = len(data200)\n",
    "data200 = data200.reshape(len_Data_200,-1)\n",
    "#Labels em ordem dos dados\n",
    "labels200 = generator200.classes\n",
    "num_classes200 = len(generator200.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar 5 divisoes do conjunto em treino e teste de magnitude 200x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X200_train1, X200_test1, y200_train1, y200_test1 = train_test_split(data200, labels200, random_state=0, train_size=0.7)\n",
    "X200_train2, X200_test2, y200_train2, y200_test2 = train_test_split(data200, labels200, random_state=1, train_size=0.7)\n",
    "X200_train3, X200_test3, y200_train3, y200_test3 = train_test_split(data200, labels200, random_state=2, train_size=0.7)\n",
    "X200_train4, X200_test4, y200_train4, y200_test4 = train_test_split(data200, labels200, random_state=3, train_size=0.7)\n",
    "X200_train5, X200_test5, y200_train5, y200_test5 = train_test_split(data200, labels200, random_state=4, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar os dados de treino e teste e labels magnitude 200x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('X200_train1.npy', X200_train1)\n",
    "np.save('X200_train2.npy', X200_train2)\n",
    "np.save('X200_train3.npy', X200_train3)\n",
    "np.save('X200_train4.npy', X200_train4)\n",
    "np.save('X200_train5.npy', X200_train5)\n",
    "\n",
    "np.save('X200_test1.npy', X200_test1)\n",
    "np.save('X200_test2.npy', X200_test2)\n",
    "np.save('X200_test3.npy', X200_test3)\n",
    "np.save('X200_test4.npy', X200_test4)\n",
    "np.save('X200_test5.npy', X200_test5)\n",
    "\n",
    "np.save('y200_train1.npy', y200_train1)\n",
    "np.save('y200_train2.npy', y200_train2)\n",
    "np.save('y200_train3.npy', y200_train3)\n",
    "np.save('y200_train4.npy', y200_train4)\n",
    "np.save('y200_train5.npy', y200_train5)\n",
    "\n",
    "np.save('y200_test1.npy', y200_test1)\n",
    "np.save('y200_test2.npy', y200_test2)\n",
    "np.save('y200_test3.npy', y200_test3)\n",
    "np.save('y200_test4.npy', y200_test4)\n",
    "np.save('y200_test5.npy', y200_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados 400x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1820 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#Carregando fator 400x\n",
    "generator400 = datagen.flow_from_directory(\n",
    "    data_dir400,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "#Features extraidas\n",
    "data400 = np.load('bottleneck_features_400.npy')\n",
    "len_Data_400 = len(data400)\n",
    "data400 = data400.reshape(len_Data_400,-1)\n",
    "#Labels em ordem dos dados\n",
    "labels400 = generator400.classes\n",
    "num_classes400 = len(generator400.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar 5 divisoes do conjunto em treino e teste de magnitude 400x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X400_train1, X400_test1, y400_train1, y400_test1 = train_test_split(data400, labels400, random_state=0, train_size=0.7)\n",
    "X400_train2, X400_test2, y400_train2, y400_test2 = train_test_split(data400, labels400, random_state=1, train_size=0.7)\n",
    "X400_train3, X400_test3, y400_train3, y400_test3 = train_test_split(data400, labels400, random_state=2, train_size=0.7)\n",
    "X400_train4, X400_test4, y400_train4, y400_test4 = train_test_split(data400, labels400, random_state=3, train_size=0.7)\n",
    "X400_train5, X400_test5, y400_train5, y400_test5 = train_test_split(data400, labels400, random_state=4, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar os dados de treino e teste e labels magnitude 400x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('X400_train1.npy', X400_train1)\n",
    "np.save('X400_train2.npy', X400_train2)\n",
    "np.save('X400_train3.npy', X400_train3)\n",
    "np.save('X400_train4.npy', X400_train4)\n",
    "np.save('X400_train5.npy', X400_train5)\n",
    "\n",
    "np.save('X400_test1.npy', X400_test1)\n",
    "np.save('X400_test2.npy', X400_test2)\n",
    "np.save('X400_test3.npy', X400_test3)\n",
    "np.save('X400_test4.npy', X400_test4)\n",
    "np.save('X400_test5.npy', X400_test5)\n",
    "\n",
    "np.save('y400_train1.npy', y400_train1)\n",
    "np.save('y400_train2.npy', y400_train2)\n",
    "np.save('y400_train3.npy', y400_train3)\n",
    "np.save('y400_train4.npy', y400_train4)\n",
    "np.save('y400_train5.npy', y400_train5)\n",
    "\n",
    "np.save('y400_test1.npy', y400_test1)\n",
    "np.save('y400_test2.npy', y400_test2)\n",
    "np.save('y400_test3.npy', y400_test3)\n",
    "np.save('y400_test4.npy', y400_test4)\n",
    "np.save('y400_test5.npy', y400_test5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
